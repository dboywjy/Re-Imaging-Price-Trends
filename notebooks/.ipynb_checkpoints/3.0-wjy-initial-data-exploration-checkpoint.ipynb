{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c90c782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e4e05be",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 54000 into shape (46080)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m300\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m46080\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 54000 into shape (46080)"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(3, 60, 300)\n",
    "x = x.reshape(-1,46080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1281d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c9acd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first\n",
      "[80, 60]\n",
      "[40, 60]\n",
      "second\n",
      "[56, 60]\n",
      "[28, 60]\n",
      "third\n",
      "[44, 60]\n",
      "[22, 60]\n"
     ]
    }
   ],
   "source": [
    "from math import floor\n",
    "def conv2d_hw(H, W, kernel, dilation, padding, stride):\n",
    "    H2 = floor((H+2*padding[0] - dilation[0]*(kernel[0] - 1) - 1) / stride[0] + 1)\n",
    "    W2 = floor((W+2*padding[1] - dilation[1]*(kernel[1] - 1) - 1) / stride[1] + 1)\n",
    "    return [H2, W2]\n",
    "\n",
    "def maxpool_hw(H, W, kernel, dilation, padding, stride):\n",
    "    H2 = floor((H+2*padding[0] - dilation[0]*(kernel[0] - 1) - 1) / stride[0] + 1)\n",
    "    W2 = floor((W+2*padding[1] - dilation[1]*(kernel[1] - 1) - 1) / stride[1] + 1)\n",
    "    return [H2, W2]\n",
    "## \n",
    "H, W = 64, 60\n",
    "\n",
    "# conv2d\n",
    "kernel = [5, 3]\n",
    "dilation = [1, 1]\n",
    "padding = [10, 1]\n",
    "stride = [1, 1]\n",
    "\n",
    "# maxpool\n",
    "kernel2 = [2, 1]\n",
    "dilation2 = [1, 1] #init\n",
    "padding2 = [0, 0]\n",
    "stride2 = [2, 1]\n",
    "\n",
    "print('first')\n",
    "[H, W] = conv2d_hw(H, W, kernel, dilation, padding, stride)\n",
    "print([H, W])\n",
    "\n",
    "[H, W] = maxpool_hw(H, W, kernel2, dilation2, padding2, stride2)\n",
    "print([H, W])\n",
    "\n",
    "print('second')\n",
    "[H, W] = conv2d_hw(H, W, kernel, dilation, padding, stride)\n",
    "print([H, W])\n",
    "\n",
    "[H, W] = maxpool_hw(H, W, kernel2, dilation2, padding2, stride2)\n",
    "print([H, W])\n",
    "\n",
    "print('third')\n",
    "[H, W] = conv2d_hw(H, W, kernel, dilation, padding, stride)\n",
    "print([H, W])\n",
    "\n",
    "[H, W] = maxpool_hw(H, W, kernel2, dilation2, padding2, stride2)\n",
    "print([H, W])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82410233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337920"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "22*60*256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a09a1284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 46080/256/60/3\n",
    "from utils.utils import *\n",
    "m = nn.MaxPool2d((3, 2), stride=(2, 1))\n",
    "input1 = torch.randn(2, 1, 64, 60)\n",
    "output = m(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76e9f3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 64, 60]), torch.Size([2, 1, 31, 59]), [31, 59])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1.shape, output.shape, maxpool_hw(64, 60, [3, 2], [1, 1], [0, 0], [2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06b5990f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jwangiy/Reimage/my_reimagine/project/notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2996ea2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first\n",
      "[26, 60]\n",
      "[13, 60]\n",
      "second\n",
      "[9, 60]\n",
      "[4, 60]\n",
      "third\n",
      "[6, 60]\n",
      "[3, 60]\n"
     ]
    }
   ],
   "source": [
    "from math import floor\n",
    "def conv2d_hw(H, W, kernel, dilation, padding, stride):\n",
    "    H2 = floor((H+2*padding[0] - dilation[0]*(kernel[0] - 1) - 1) / stride[0] + 1)\n",
    "    W2 = floor((W+2*padding[1] - dilation[1]*(kernel[1] - 1) - 1) / stride[1] + 1)\n",
    "    return [H2, W2]\n",
    "\n",
    "def maxpool_hw(H, W, kernel, dilation, padding, stride):\n",
    "    H2 = floor((H+2*padding[0] - dilation[0]*(kernel[0] - 1) - 1) / stride[0] + 1)\n",
    "    W2 = floor((W+2*padding[1] - dilation[1]*(kernel[1] - 1) - 1) / stride[1] + 1)\n",
    "    return [H2, W2]\n",
    "## \n",
    "H, W = 64, 60\n",
    "\n",
    "# conv2d\n",
    "kernel = [5, 3]\n",
    "dilation = [2, 1]\n",
    "padding = [10, 1]\n",
    "stride = [3, 1]\n",
    "\n",
    "# maxpool\n",
    "kernel2 = [2, 1]\n",
    "dilation2 = [1, 1] #init\n",
    "padding2 = [0, 0]\n",
    "stride2 = [2, 1]\n",
    "\n",
    "print('first')\n",
    "[H, W] = conv2d_hw(H, W, kernel, dilation, padding, stride)\n",
    "print([H, W])\n",
    "\n",
    "[H, W] = maxpool_hw(H, W, kernel2, dilation2, padding2, stride2)\n",
    "print([H, W])\n",
    "\n",
    "print('second')\n",
    "[H, W] = conv2d_hw(H, W, kernel, dilation, padding, stride)\n",
    "print([H, W])\n",
    "\n",
    "[H, W] = maxpool_hw(H, W, kernel2, dilation2, padding2, stride2)\n",
    "print([H, W])\n",
    "\n",
    "print('third')\n",
    "[H, W] = conv2d_hw(H, W, kernel, dilation, padding, stride)\n",
    "print([H, W])\n",
    "\n",
    "[H, W] = maxpool_hw(H, W, kernel2, dilation2, padding2, stride2)\n",
    "print([H, W])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9946f0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "def conv2d_hw(h, w, kernel1, dilation1, padding1, stride1):\n",
    "    h = floor((h+2*padding1[0] - dilation1[0]*(kernel1[0] - 1) - 1) / stride1[0] + 1)\n",
    "    w = floor((w+2*padding1[1] - dilation1[1]*(kernel1[1] - 1) - 1) / stride1[1] + 1)\n",
    "    return [h, w]\n",
    "\n",
    "def maxpool_hw(HH, WW, kernel2, dilation2, padding2, stride2):\n",
    "    HHH = floor((HH+2*padding2[0] - dilation2[0]*(kernel2[0] - 1) - 1) / stride2[0] + 1)\n",
    "    WWW = floor((WW+2*padding2[1] - dilation2[1]*(kernel2[1] - 1) - 1) / stride2[1] + 1)\n",
    "    return [HHH, WWW]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7a4594d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first\n",
      "[33, 60]\n",
      "[11, 60]\n"
     ]
    }
   ],
   "source": [
    "H, W = 64, 60\n",
    "\n",
    "# conv2d\n",
    "kernel = [5, 3]\n",
    "dilation = [2, 1]\n",
    "padding = [21, 1]\n",
    "stride = [3, 1]\n",
    "\n",
    "# maxpool\n",
    "kernel2 = [2, 1]\n",
    "dilation2 = [2, 1] #init\n",
    "padding2 = [0, 0]\n",
    "stride2 = [3, 1]\n",
    "\n",
    "print('first')\n",
    "[H, W] = conv2d_hw(H, W, kernel, dilation, padding, stride)\n",
    "print([H, W])\n",
    "\n",
    "[H, W] = maxpool_hw(H, W, kernel2, dilation2, padding2, stride2)\n",
    "print([H, W])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "99e7e0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first\n",
      "[9, 60]\n",
      "[8, 60]\n"
     ]
    }
   ],
   "source": [
    "H, W = 11, 60\n",
    "\n",
    "# conv2d\n",
    "kernel = [5, 3]\n",
    "dilation = [1, 1]\n",
    "padding = [1, 1]\n",
    "stride = [1, 1]\n",
    "\n",
    "# maxpool\n",
    "kernel2 = [2, 1]\n",
    "dilation2 = [1, 1] #init\n",
    "padding2 = [0, 0]\n",
    "stride2 = [1, 1]\n",
    "\n",
    "print('first')\n",
    "[H, W] = conv2d_hw(H, W, kernel, dilation, padding, stride)\n",
    "print([H, W])\n",
    "\n",
    "[H, W] = maxpool_hw(H, W, kernel2, dilation2, padding2, stride2)\n",
    "print([H, W])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b6d804d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first\n",
      "[4, 60]\n",
      "[3, 60]\n"
     ]
    }
   ],
   "source": [
    "H, W = 8, 60\n",
    "\n",
    "# conv2d\n",
    "kernel = [5, 3]\n",
    "dilation = [1, 1]\n",
    "padding = [0, 1]\n",
    "stride = [1, 1]\n",
    "\n",
    "# maxpool\n",
    "kernel2 = [2, 1]\n",
    "dilation2 = [1, 1] #init\n",
    "padding2 = [0, 0]\n",
    "stride2 = [1, 1]\n",
    "\n",
    "print('first')\n",
    "[H, W] = conv2d_hw(H, W, kernel, dilation, padding, stride)\n",
    "print([H, W])\n",
    "\n",
    "[H, W] = maxpool_hw(H, W, kernel2, dilation2, padding2, stride2)\n",
    "print([H, W])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f3b40b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1182720, 3.3333333333333335)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "77*60*256, 46080/256/54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efec7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb00983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d478dcdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96067ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7747d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d59b0c90",
   "metadata": {},
   "source": [
    "#### exploration4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11105901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from models.model_reg import *\n",
    "from utils.utils import *\n",
    "from utils.data import DataLoad\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209c68c9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9a9df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from models.model_reg import *\n",
    "from utils.utils import *\n",
    "from utils.data import DataLoad\n",
    "import config\n",
    "\n",
    "class Train():\n",
    "    def __init__(self):\n",
    "        self.IMAGE_WIDTH = config.IMAGE_WIDTH\n",
    "        self.IMAGE_HEIGHT = config.IMAGE_HEIGHT\n",
    "        self.train_val_years = config.train_val_years\n",
    "        self.test_years = config.test_years\n",
    "        self.target = config.trainer_reg['target']\n",
    "        self.path = config.trainer_reg['path']\n",
    "        self.params = config.trainer_reg\n",
    "\n",
    "    def dataStep(self):\n",
    "        data = DataLoad(self.IMAGE_WIDTH, self.IMAGE_HEIGHT, self.train_val_years, self.test_years, self.target, self.path, self.params['batch_size'])\n",
    "        [self.train_loader, self.val_loader, self.test_loader] = data.main()\n",
    "    \n",
    "    def model(self):\n",
    "        model = CNN()\n",
    "        self.device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.device_ids=range(torch.cuda.device_count())\n",
    "        model.cuda(device=self.device_ids[3])\n",
    "        self.model = model \n",
    "        self.loss_func = torch.nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(),lr=self.params['init_lr'])\n",
    "\n",
    "        self.early_stopping = EarlyStopping(patience = self.params['early_stopping_patience'],delta = self.params['early_stopping_delta'], path= self.params['early_stopping_path'],verbose=True)\n",
    "\n",
    "    def train(self):\n",
    "        self.loss_count = []\n",
    "        epochs = self.params['epoch']\n",
    "        self.global_loss_train = []\n",
    "        self.global_loss_test = []\n",
    "        self.global_loss_val = []\n",
    "\n",
    "        lr = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            for i,(x,y) in enumerate(self.train_loader):\n",
    "                batch_x = Variable(x.cuda(device=self.device_ids[3]))\n",
    "                batch_y = Variable(y.cuda(device=self.device_ids[3]))\n",
    "                out = self.model(batch_x.float())\n",
    "                loss = self.loss_func(out,batch_y.squeeze().long())\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward() \n",
    "                self.optimizer.step()\n",
    "                if i%20 == 0:\n",
    "                    temp = loss.cpu()\n",
    "                    self.loss_count.append(temp.detach().numpy())\n",
    "                    print('epoch:', format(epoch+1),f'iteration: {i+1}:\\t','loss:', loss.item())\n",
    "                    \n",
    "            \n",
    "            loss_val_epoch = [] \n",
    "            for x,y in self.val_loader:\n",
    "                batch_x = Variable(x.cuda(device=self.device_ids[3]))\n",
    "                batch_y = Variable(y.cuda(device=self.device_ids[3]))\n",
    "                prediction = self.model(batch_x)\n",
    "                loss = self.loss_func(prediction, batch_y.squeeze().long())\n",
    "                loss_val_epoch.append(loss.cpu().detach().numpy())\n",
    "                \n",
    "            loss_val = np.mean(loss_val_epoch)\n",
    "            self.global_loss_val.append(loss_val)\n",
    "\n",
    "            loss_train = self.loss_count[-1]\n",
    "            self.global_loss_train.append(loss_train)\n",
    "            \n",
    "            self.early_stopping(loss_val, self.model)\n",
    "            if self.early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "            print('----------------epoch '+str(epoch+1)+' end---------------------')\n",
    "        self.lr = lr\n",
    "        self.model = torch.load(self.params['early_stopping_path'])\n",
    "        \n",
    "    def evaluate(self):\n",
    "        self.model = torch.load(self.params['early_stopping_path'])\n",
    "        #########################################################################\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.title('PyTorch_CNN_Loss')\n",
    "        plt.plot(self.loss_count,label='Loss')\n",
    "        plt.plot(pd.DataFrame(np.array(self.loss_count)).rolling(20,1).mean(),label='MA Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig('./reports/figures/trainer_reg_CNN_classification_loss.png')\n",
    "        plt.show()\n",
    "        \n",
    "        #########################################################################\n",
    "        epochs = range(1, len(self.global_loss_train) + 1)\n",
    "        minposs = self.global_loss_val.index(self.early_stopping.val_loss_min.tolist())+1\n",
    "        fig,ax=plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "        ax[0].plot(epochs, self.global_loss_train, '.', label='Train')\n",
    "        ax[0].plot(epochs, self.global_loss_train,'r')\n",
    "        ax[0].axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
    "        ax[0].legend()\n",
    "        ax[0].set_title('train_loss')\n",
    "        ax[1].plot(epochs, self.global_loss_val, '.', label='Val')\n",
    "        ax[1].plot(epochs, self.global_loss_val,'r')\n",
    "        ax[1].axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
    "        ax[1].legend()\n",
    "        ax[1].set_title('val_loss')\n",
    "        plt.savefig('./reports/figures/trainer_reg_CNN_classification_train_val_loss.png')\n",
    "        plt.show()\n",
    "\n",
    "        data = DataLoad(config.IMAGE_WIDTH, config.IMAGE_HEIGHT, config.train_val_years, config.test_years, self.params['target'], self.params['path'], self.params['batch_size'])\n",
    "        [x_train, x_val, y_train, y_val, images_test, label_test] = data.processing_data()\n",
    "        \n",
    "        #########################################################################\n",
    "        prediction = []\n",
    "        device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "        device_ids=range(torch.cuda.device_count())\n",
    "        global_loss_test = []\n",
    "        with torch.no_grad():\n",
    "            for images,labels in self.test_loader:\n",
    "                test_x = Variable(images.cuda(device=device_ids[3]))\n",
    "                test_y = Variable(labels.cuda(device=device_ids[3]))\n",
    "                prediction_test = self.model(test_x)\n",
    "                prediction.extend(torch.max(prediction_test,1)[1].cpu().numpy().tolist())\n",
    "                loss_test = self.loss_func(prediction_test, test_y.squeeze().long())\n",
    "                global_loss_test.append(loss_test.cpu().detach().numpy())\n",
    "        label_test['pred'] = prediction\n",
    "        cm = confusion_matrix(label_test[self.params['target']], label_test['pred'])\n",
    "        print(\"Test Accuracy\", (cm[0][0]+cm[1][1])/np.sum(cm))\n",
    "        print('Test Loss', np.mean(global_loss_test))\n",
    "        print(\"Test Pearsonr:\", scipy.stats.pearsonr(label_test[self.params['target']], label_test['pred'])[0])\n",
    "        print(\"Test Spearmanr:\", scipy.stats.spearmanr(label_test[self.params['target']], label_test['pred'])[0])\n",
    "        \n",
    "        #########################################################################\n",
    "        prediction = []\n",
    "        global_loss_val = []\n",
    "        with torch.no_grad():\n",
    "            for images,labels in self.val_loader:\n",
    "                val_x = Variable(images.cuda(device=device_ids[3]))\n",
    "                val_y = Variable(labels.cuda(device=device_ids[3]))\n",
    "                prediction_val = self.model(val_x)\n",
    "                prediction.extend(torch.max(prediction_val,1)[1].cpu().numpy().tolist())\n",
    "                loss_val = self.loss_func(prediction_val, val_y.squeeze().long())\n",
    "                global_loss_val.append(loss_val.cpu().detach().numpy())\n",
    "        y_val['pred'] = prediction\n",
    "        cm = confusion_matrix(y_val[self.params['target']], y_val['pred'])\n",
    "        print(\"Val Accuracy\", (cm[0][0]+cm[1][1])/np.sum(cm))\n",
    "        print('Val Loss', np.mean(global_loss_val))\n",
    "        \n",
    "        #########################################################################\n",
    "        \n",
    "        \n",
    "    def main(self):\n",
    "        print(f\"{'DATA':-^60}\")\n",
    "        self.dataStep()\n",
    "        print(f\"{'Init Model':-^60}\")\n",
    "        self.model()\n",
    "        print(f\"{'Train Model':-^60}\")\n",
    "        self.train()\n",
    "        print(f\"{'Evaluate Model':-^60}\")\n",
    "        self.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d057cd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from trainers.trainer_reg import Train\n",
    "\n",
    "train = Train()\n",
    "train.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b7e1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e838a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc95cb88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37593474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
