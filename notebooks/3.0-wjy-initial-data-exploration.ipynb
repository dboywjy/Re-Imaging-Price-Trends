{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c90c782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e4e05be",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 54000 into shape (46080)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m300\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m46080\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 54000 into shape (46080)"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(3, 60, 300)\n",
    "x = x.reshape(-1,46080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1281d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c9acd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first\n",
      "[80, 60]\n",
      "[40, 60]\n",
      "second\n",
      "[56, 60]\n",
      "[28, 60]\n",
      "third\n",
      "[44, 60]\n",
      "[22, 60]\n"
     ]
    }
   ],
   "source": [
    "from math import floor\n",
    "def conv2d_hw(H, W, kernel, dilation, padding, stride):\n",
    "    H2 = floor((H+2*padding[0] - dilation[0]*(kernel[0] - 1) - 1) / stride[0] + 1)\n",
    "    W2 = floor((W+2*padding[1] - dilation[1]*(kernel[1] - 1) - 1) / stride[1] + 1)\n",
    "    return [H2, W2]\n",
    "\n",
    "def maxpool_hw(H, W, kernel, dilation, padding, stride):\n",
    "    H2 = floor((H+2*padding[0] - dilation[0]*(kernel[0] - 1) - 1) / stride[0] + 1)\n",
    "    W2 = floor((W+2*padding[1] - dilation[1]*(kernel[1] - 1) - 1) / stride[1] + 1)\n",
    "    return [H2, W2]\n",
    "## \n",
    "H, W = 64, 60\n",
    "\n",
    "# conv2d\n",
    "kernel = [5, 3]\n",
    "dilation = [1, 1]\n",
    "padding = [10, 1]\n",
    "stride = [1, 1]\n",
    "\n",
    "# maxpool\n",
    "kernel2 = [2, 1]\n",
    "dilation2 = [1, 1] #init\n",
    "padding2 = [0, 0]\n",
    "stride2 = [2, 1]\n",
    "\n",
    "print('first')\n",
    "[H, W] = conv2d_hw(H, W, kernel, dilation, padding, stride)\n",
    "print([H, W])\n",
    "\n",
    "[H, W] = maxpool_hw(H, W, kernel2, dilation2, padding2, stride2)\n",
    "print([H, W])\n",
    "\n",
    "print('second')\n",
    "[H, W] = conv2d_hw(H, W, kernel, dilation, padding, stride)\n",
    "print([H, W])\n",
    "\n",
    "[H, W] = maxpool_hw(H, W, kernel2, dilation2, padding2, stride2)\n",
    "print([H, W])\n",
    "\n",
    "print('third')\n",
    "[H, W] = conv2d_hw(H, W, kernel, dilation, padding, stride)\n",
    "print([H, W])\n",
    "\n",
    "[H, W] = maxpool_hw(H, W, kernel2, dilation2, padding2, stride2)\n",
    "print([H, W])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82410233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337920"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "22*60*256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a09a1284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 46080/256/60/3\n",
    "from utils.utils import *\n",
    "m = nn.MaxPool2d((3, 2), stride=(2, 1))\n",
    "input1 = torch.randn(2, 1, 64, 60)\n",
    "output = m(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76e9f3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 64, 60]), torch.Size([2, 1, 31, 59]), [31, 59])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1.shape, output.shape, maxpool_hw(64, 60, [3, 2], [1, 1], [0, 0], [2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06b5990f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jwangiy/Reimage/my_reimagine/project/notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2996ea2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first\n",
      "[26, 60]\n",
      "[13, 60]\n",
      "second\n",
      "[9, 60]\n",
      "[4, 60]\n",
      "third\n",
      "[6, 60]\n",
      "[3, 60]\n"
     ]
    }
   ],
   "source": [
    "from math import floor\n",
    "def conv2d_hw(H, W, kernel, dilation, padding, stride):\n",
    "    H2 = floor((H+2*padding[0] - dilation[0]*(kernel[0] - 1) - 1) / stride[0] + 1)\n",
    "    W2 = floor((W+2*padding[1] - dilation[1]*(kernel[1] - 1) - 1) / stride[1] + 1)\n",
    "    return [H2, W2]\n",
    "\n",
    "def maxpool_hw(H, W, kernel, dilation, padding, stride):\n",
    "    H2 = floor((H+2*padding[0] - dilation[0]*(kernel[0] - 1) - 1) / stride[0] + 1)\n",
    "    W2 = floor((W+2*padding[1] - dilation[1]*(kernel[1] - 1) - 1) / stride[1] + 1)\n",
    "    return [H2, W2]\n",
    "## \n",
    "H, W = 64, 60\n",
    "\n",
    "# conv2d\n",
    "kernel = [5, 3]\n",
    "dilation = [2, 1]\n",
    "padding = [10, 1]\n",
    "stride = [3, 1]\n",
    "\n",
    "# maxpool\n",
    "kernel2 = [2, 1]\n",
    "dilation2 = [1, 1] #init\n",
    "padding2 = [0, 0]\n",
    "stride2 = [2, 1]\n",
    "\n",
    "print('first')\n",
    "[H, W] = conv2d_hw(H, W, kernel, dilation, padding, stride)\n",
    "print([H, W])\n",
    "\n",
    "[H, W] = maxpool_hw(H, W, kernel2, dilation2, padding2, stride2)\n",
    "print([H, W])\n",
    "\n",
    "print('second')\n",
    "[H, W] = conv2d_hw(H, W, kernel, dilation, padding, stride)\n",
    "print([H, W])\n",
    "\n",
    "[H, W] = maxpool_hw(H, W, kernel2, dilation2, padding2, stride2)\n",
    "print([H, W])\n",
    "\n",
    "print('third')\n",
    "[H, W] = conv2d_hw(H, W, kernel, dilation, padding, stride)\n",
    "print([H, W])\n",
    "\n",
    "[H, W] = maxpool_hw(H, W, kernel2, dilation2, padding2, stride2)\n",
    "print([H, W])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9946f0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "def conv2d_hw(h, w, kernel1, dilation1, padding1, stride1):\n",
    "    h = floor((h+2*padding1[0] - dilation1[0]*(kernel1[0] - 1) - 1) / stride1[0] + 1)\n",
    "    w = floor((w+2*padding1[1] - dilation1[1]*(kernel1[1] - 1) - 1) / stride1[1] + 1)\n",
    "    return [h, w]\n",
    "\n",
    "def maxpool_hw(HH, WW, kernel2, dilation2, padding2, stride2):\n",
    "    HHH = floor((HH+2*padding2[0] - dilation2[0]*(kernel2[0] - 1) - 1) / stride2[0] + 1)\n",
    "    WWW = floor((WW+2*padding2[1] - dilation2[1]*(kernel2[1] - 1) - 1) / stride2[1] + 1)\n",
    "    return [HHH, WWW]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7a4594d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first\n",
      "[33, 60]\n",
      "[11, 60]\n"
     ]
    }
   ],
   "source": [
    "H, W = 64, 60\n",
    "\n",
    "# conv2d\n",
    "kernel = [5, 3]\n",
    "dilation = [2, 1]\n",
    "padding = [21, 1]\n",
    "stride = [3, 1]\n",
    "\n",
    "# maxpool\n",
    "kernel2 = [2, 1]\n",
    "dilation2 = [2, 1] #init\n",
    "padding2 = [0, 0]\n",
    "stride2 = [3, 1]\n",
    "\n",
    "print('first')\n",
    "[H, W] = conv2d_hw(H, W, kernel, dilation, padding, stride)\n",
    "print([H, W])\n",
    "\n",
    "[H, W] = maxpool_hw(H, W, kernel2, dilation2, padding2, stride2)\n",
    "print([H, W])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "99e7e0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first\n",
      "[9, 60]\n",
      "[8, 60]\n"
     ]
    }
   ],
   "source": [
    "H, W = 11, 60\n",
    "\n",
    "# conv2d\n",
    "kernel = [5, 3]\n",
    "dilation = [1, 1]\n",
    "padding = [1, 1]\n",
    "stride = [1, 1]\n",
    "\n",
    "# maxpool\n",
    "kernel2 = [2, 1]\n",
    "dilation2 = [1, 1] #init\n",
    "padding2 = [0, 0]\n",
    "stride2 = [1, 1]\n",
    "\n",
    "print('first')\n",
    "[H, W] = conv2d_hw(H, W, kernel, dilation, padding, stride)\n",
    "print([H, W])\n",
    "\n",
    "[H, W] = maxpool_hw(H, W, kernel2, dilation2, padding2, stride2)\n",
    "print([H, W])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b6d804d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first\n",
      "[4, 60]\n",
      "[3, 60]\n"
     ]
    }
   ],
   "source": [
    "H, W = 8, 60\n",
    "\n",
    "# conv2d\n",
    "kernel = [5, 3]\n",
    "dilation = [1, 1]\n",
    "padding = [0, 1]\n",
    "stride = [1, 1]\n",
    "\n",
    "# maxpool\n",
    "kernel2 = [2, 1]\n",
    "dilation2 = [1, 1] #init\n",
    "padding2 = [0, 0]\n",
    "stride2 = [1, 1]\n",
    "\n",
    "print('first')\n",
    "[H, W] = conv2d_hw(H, W, kernel, dilation, padding, stride)\n",
    "print([H, W])\n",
    "\n",
    "[H, W] = maxpool_hw(H, W, kernel2, dilation2, padding2, stride2)\n",
    "print([H, W])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f3b40b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1182720, 3.3333333333333335)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "77*60*256, 46080/256/54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efec7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb00983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327c93b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a11c6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bea12d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a528f499",
   "metadata": {},
   "source": [
    "#### exploration4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31cf1efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from models.model_reg import *\n",
    "from utils.utils import *\n",
    "from utils.data import DataLoad\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b167dddb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e327cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append(\"..\")\n",
    "# from models.model_reg import *\n",
    "# from utils.utils import *\n",
    "# from utils.data import DataLoad\n",
    "# import config\n",
    "\n",
    "# class Train():\n",
    "#     def __init__(self):\n",
    "#         self.IMAGE_WIDTH = config.IMAGE_WIDTH\n",
    "#         self.IMAGE_HEIGHT = config.IMAGE_HEIGHT\n",
    "#         self.train_val_years = config.train_val_years\n",
    "#         self.test_years = config.test_years\n",
    "#         self.target = config.trainer_reg['target']\n",
    "#         self.path = config.trainer_reg['path']\n",
    "#         self.params = config.trainer_reg\n",
    "\n",
    "#     def dataStep(self):\n",
    "#         data = DataLoad(self.IMAGE_WIDTH, self.IMAGE_HEIGHT, self.train_val_years, self.test_years, self.target, self.path, self.params['batch_size'])\n",
    "#         [self.train_loader, self.val_loader, self.test_loader] = data.main()\n",
    "    \n",
    "#     def model(self):\n",
    "#         model = CNN()\n",
    "#         self.device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "#         self.device_ids=range(torch.cuda.device_count())\n",
    "#         model.cuda(device=self.device_ids[3])\n",
    "#         self.model = model \n",
    "#         self.loss_func = torch.nn.MSELoss()\n",
    "#         self.optimizer = torch.optim.Adam(self.model.parameters(),lr=self.params['init_lr'])\n",
    "\n",
    "#         self.early_stopping = EarlyStopping(patience = self.params['early_stopping_patience'],delta = self.params['early_stopping_delta'], path= self.params['early_stopping_path'],verbose=True)\n",
    "\n",
    "#     def train(self):\n",
    "#         self.loss_count = []\n",
    "#         epochs = self.params['epoch']\n",
    "#         self.global_loss_train = []\n",
    "#         self.global_loss_test = []\n",
    "#         self.global_loss_val = []\n",
    "\n",
    "#         lr = []\n",
    "\n",
    "#         for epoch in range(epochs):\n",
    "            \n",
    "#             for i,(x,y) in enumerate(self.train_loader):\n",
    "#                 batch_x = Variable(x.cuda(device=self.device_ids[3]))\n",
    "#                 batch_y = Variable(y.cuda(device=self.device_ids[3]))\n",
    "#                 out = self.model(batch_x.float())\n",
    "#                 loss = self.loss_func(out,batch_y.squeeze().long())\n",
    "#                 self.optimizer.zero_grad()\n",
    "#                 loss.backward() \n",
    "#                 self.optimizer.step()\n",
    "#                 if i%20 == 0:\n",
    "#                     temp = loss.cpu()\n",
    "#                     self.loss_count.append(temp.detach().numpy())\n",
    "#                     print('epoch:', format(epoch+1),f'iteration: {i+1}:\\t','loss:', loss.item())\n",
    "                    \n",
    "            \n",
    "#             loss_val_epoch = [] \n",
    "#             for x,y in self.val_loader:\n",
    "#                 batch_x = Variable(x.cuda(device=self.device_ids[3]))\n",
    "#                 batch_y = Variable(y.cuda(device=self.device_ids[3]))\n",
    "#                 prediction = self.model(batch_x)\n",
    "#                 loss = self.loss_func(prediction, batch_y.squeeze().long())\n",
    "#                 loss_val_epoch.append(loss.cpu().detach().numpy())\n",
    "                \n",
    "#             loss_val = np.mean(loss_val_epoch)\n",
    "#             self.global_loss_val.append(loss_val)\n",
    "\n",
    "#             loss_train = self.loss_count[-1]\n",
    "#             self.global_loss_train.append(loss_train)\n",
    "            \n",
    "#             self.early_stopping(loss_val, self.model)\n",
    "#             if self.early_stopping.early_stop:\n",
    "#                 print(\"Early stopping\")\n",
    "#                 break\n",
    "#             print('----------------epoch '+str(epoch+1)+' end---------------------')\n",
    "#         self.lr = lr\n",
    "#         self.model = torch.load(self.params['early_stopping_path'])\n",
    "        \n",
    "#     def evaluate(self):\n",
    "#         self.model = torch.load(self.params['early_stopping_path'])\n",
    "#         #########################################################################\n",
    "#         plt.figure(figsize=(10,5))\n",
    "#         plt.title('PyTorch_CNN_Loss')\n",
    "#         plt.plot(self.loss_count,label='Loss')\n",
    "#         plt.plot(pd.DataFrame(np.array(self.loss_count)).rolling(20,1).mean(),label='MA Loss')\n",
    "#         plt.legend()\n",
    "#         plt.savefig('./reports/figures/trainer_reg_CNN_classification_loss.png')\n",
    "#         plt.show()\n",
    "        \n",
    "#         #########################################################################\n",
    "#         epochs = range(1, len(self.global_loss_train) + 1)\n",
    "#         minposs = self.global_loss_val.index(self.early_stopping.val_loss_min.tolist())+1\n",
    "#         fig,ax=plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "#         ax[0].plot(epochs, self.global_loss_train, '.', label='Train')\n",
    "#         ax[0].plot(epochs, self.global_loss_train,'r')\n",
    "#         ax[0].axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
    "#         ax[0].legend()\n",
    "#         ax[0].set_title('train_loss')\n",
    "#         ax[1].plot(epochs, self.global_loss_val, '.', label='Val')\n",
    "#         ax[1].plot(epochs, self.global_loss_val,'r')\n",
    "#         ax[1].axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
    "#         ax[1].legend()\n",
    "#         ax[1].set_title('val_loss')\n",
    "#         plt.savefig('./reports/figures/trainer_reg_CNN_classification_train_val_loss.png')\n",
    "#         plt.show()\n",
    "\n",
    "#         data = DataLoad(config.IMAGE_WIDTH, config.IMAGE_HEIGHT, config.train_val_years, config.test_years, self.params['target'], self.params['path'], self.params['batch_size'])\n",
    "#         [x_train, x_val, y_train, y_val, images_test, label_test] = data.processing_data()\n",
    "        \n",
    "#         #########################################################################\n",
    "#         prediction = []\n",
    "#         device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "#         device_ids=range(torch.cuda.device_count())\n",
    "#         global_loss_test = []\n",
    "#         with torch.no_grad():\n",
    "#             for images,labels in self.test_loader:\n",
    "#                 test_x = Variable(images.cuda(device=device_ids[3]))\n",
    "#                 test_y = Variable(labels.cuda(device=device_ids[3]))\n",
    "#                 prediction_test = self.model(test_x)\n",
    "#                 prediction.extend(torch.max(prediction_test,1)[1].cpu().numpy().tolist())\n",
    "#                 loss_test = self.loss_func(prediction_test, test_y.squeeze().long())\n",
    "#                 global_loss_test.append(loss_test.cpu().detach().numpy())\n",
    "#         label_test['pred'] = prediction\n",
    "#         cm = confusion_matrix(label_test[self.params['target']], label_test['pred'])\n",
    "#         print(\"Test Accuracy\", (cm[0][0]+cm[1][1])/np.sum(cm))\n",
    "#         print('Test Loss', np.mean(global_loss_test))\n",
    "#         print(\"Test Pearsonr:\", scipy.stats.pearsonr(label_test[self.params['target']], label_test['pred'])[0])\n",
    "#         print(\"Test Spearmanr:\", scipy.stats.spearmanr(label_test[self.params['target']], label_test['pred'])[0])\n",
    "        \n",
    "#         #########################################################################\n",
    "#         prediction = []\n",
    "#         global_loss_val = []\n",
    "#         with torch.no_grad():\n",
    "#             for images,labels in self.val_loader:\n",
    "#                 val_x = Variable(images.cuda(device=device_ids[3]))\n",
    "#                 val_y = Variable(labels.cuda(device=device_ids[3]))\n",
    "#                 prediction_val = self.model(val_x)\n",
    "#                 prediction.extend(torch.max(prediction_val,1)[1].cpu().numpy().tolist())\n",
    "#                 loss_val = self.loss_func(prediction_val, val_y.squeeze().long())\n",
    "#                 global_loss_val.append(loss_val.cpu().detach().numpy())\n",
    "#         y_val['pred'] = prediction\n",
    "#         cm = confusion_matrix(y_val[self.params['target']], y_val['pred'])\n",
    "#         print(\"Val Accuracy\", (cm[0][0]+cm[1][1])/np.sum(cm))\n",
    "#         print('Val Loss', np.mean(global_loss_val))\n",
    "        \n",
    "#         #########################################################################\n",
    "        \n",
    "        \n",
    "#     def main(self):\n",
    "#         print(f\"{'DATA':-^60}\")\n",
    "#         self.dataStep()\n",
    "#         print(f\"{'Init Model':-^60}\")\n",
    "#         self.model()\n",
    "#         print(f\"{'Train Model':-^60}\")\n",
    "#         self.train()\n",
    "#         print(f\"{'Evaluate Model':-^60}\")\n",
    "#         self.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d49feb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------DATA----------------------------\n",
      "------------Data Processing-------------\n",
      "-------------get_dataloader-------------\n",
      "-------------------------Init Model-------------------------\n",
      "./cnn_model/trainer12_ret_20_classification_model_stat_checkpoint.pt\n",
      "------------------------Train Model-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwangiy/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 iteration: 1:\t loss: 0.5726826190948486\n",
      "epoch: 1 iteration: 21:\t loss: 0.04938488453626633\n",
      "epoch: 1 iteration: 41:\t loss: 0.02411958947777748\n",
      "epoch: 1 iteration: 61:\t loss: 0.014821433462202549\n",
      "epoch: 1 iteration: 81:\t loss: 0.015520451590418816\n",
      "epoch: 1 iteration: 101:\t loss: 0.015684323385357857\n",
      "epoch: 1 iteration: 121:\t loss: 0.01912873610854149\n",
      "epoch: 1 iteration: 141:\t loss: 0.010555725544691086\n",
      "epoch: 1 iteration: 161:\t loss: 0.012616466730833054\n",
      "epoch: 1 iteration: 181:\t loss: 0.008317268453538418\n",
      "epoch: 1 iteration: 201:\t loss: 0.008622458204627037\n",
      "epoch: 1 iteration: 221:\t loss: 0.007907411083579063\n",
      "epoch: 1 iteration: 241:\t loss: 0.006285147275775671\n",
      "epoch: 1 iteration: 261:\t loss: 0.005956212058663368\n",
      "epoch: 1 iteration: 281:\t loss: 0.0055236006155610085\n",
      "epoch: 1 iteration: 301:\t loss: 0.005467331036925316\n",
      "epoch: 1 iteration: 321:\t loss: 0.005594657268375158\n",
      "epoch: 1 iteration: 341:\t loss: 0.005994855426251888\n",
      "epoch: 1 iteration: 361:\t loss: 0.004842751659452915\n",
      "epoch: 1 iteration: 381:\t loss: 0.0049695721827447414\n",
      "epoch: 1 iteration: 401:\t loss: 0.0036763567477464676\n",
      "epoch: 1 iteration: 421:\t loss: 0.005613152869045734\n",
      "epoch: 1 iteration: 441:\t loss: 0.0043678791262209415\n",
      "epoch: 1 iteration: 461:\t loss: 0.003225066000595689\n",
      "epoch: 1 iteration: 481:\t loss: 0.0043146344833076\n",
      "epoch: 1 iteration: 501:\t loss: 0.01150341797620058\n",
      "epoch: 1 iteration: 521:\t loss: 0.011153006926178932\n",
      "epoch: 1 iteration: 541:\t loss: 0.004383252467960119\n",
      "epoch: 1 iteration: 561:\t loss: 0.0038677819538861513\n",
      "epoch: 1 iteration: 581:\t loss: 0.0033167426008731127\n",
      "epoch: 1 iteration: 601:\t loss: 0.0033855224028229713\n",
      "epoch: 1 iteration: 621:\t loss: 0.003756274003535509\n",
      "epoch: 1 iteration: 641:\t loss: 0.004299257881939411\n",
      "epoch: 1 iteration: 661:\t loss: 0.0036750526633113623\n",
      "epoch: 1 iteration: 681:\t loss: 0.0027369651943445206\n",
      "epoch: 1 iteration: 701:\t loss: 0.0037264933343976736\n",
      "epoch: 1 iteration: 721:\t loss: 0.003232019254937768\n",
      "epoch: 1 iteration: 741:\t loss: 0.00399246159940958\n",
      "epoch: 1 iteration: 761:\t loss: 0.002742158714681864\n",
      "epoch: 1 iteration: 781:\t loss: 0.002707407809793949\n",
      "epoch: 1 iteration: 801:\t loss: 0.002751929685473442\n",
      "epoch: 1 iteration: 821:\t loss: 0.002614709548652172\n",
      "epoch: 1 iteration: 841:\t loss: 0.0024398784153163433\n",
      "epoch: 1 iteration: 861:\t loss: 0.002973125781863928\n",
      "epoch: 1 iteration: 881:\t loss: 0.002631913870573044\n",
      "epoch: 1 iteration: 901:\t loss: 0.003310562577098608\n",
      "epoch: 1 iteration: 921:\t loss: 0.002626013709232211\n",
      "epoch: 1 iteration: 941:\t loss: 0.002124832011759281\n",
      "epoch: 1 iteration: 961:\t loss: 0.0026939143426716328\n",
      "epoch: 1 iteration: 981:\t loss: 0.002515557687729597\n",
      "epoch: 1 iteration: 1001:\t loss: 0.002326612826436758\n",
      "epoch: 1 iteration: 1021:\t loss: 0.0022646798752248287\n",
      "epoch: 1 iteration: 1041:\t loss: 0.003183696884661913\n",
      "epoch: 1 iteration: 1061:\t loss: 0.002591224852949381\n",
      "epoch: 1 iteration: 1081:\t loss: 0.002580153290182352\n",
      "epoch: 1 iteration: 1101:\t loss: 0.0023658168502151966\n",
      "epoch: 1 iteration: 1121:\t loss: 0.002353643998503685\n",
      "epoch: 1 iteration: 1141:\t loss: 0.009666050784289837\n",
      "epoch: 1 iteration: 1161:\t loss: 0.002660631202161312\n",
      "epoch: 1 iteration: 1181:\t loss: 0.010240087285637856\n",
      "epoch: 1 iteration: 1201:\t loss: 0.0024820154067128897\n",
      "epoch: 1 iteration: 1221:\t loss: 0.00996731873601675\n",
      "epoch: 1 iteration: 1241:\t loss: 0.002455320442095399\n",
      "epoch: 1 iteration: 1261:\t loss: 0.0018922047456726432\n",
      "epoch: 1 iteration: 1281:\t loss: 0.0021430724300444126\n",
      "epoch: 1 iteration: 1301:\t loss: 0.0021229186095297337\n",
      "epoch: 1 iteration: 1321:\t loss: 0.002130544278770685\n",
      "epoch: 1 iteration: 1341:\t loss: 0.0019127361010760069\n",
      "epoch: 1 iteration: 1361:\t loss: 0.002265642397105694\n",
      "epoch: 1 iteration: 1381:\t loss: 0.002006709575653076\n",
      "epoch: 1 iteration: 1401:\t loss: 0.002016557613387704\n",
      "epoch: 1 iteration: 1421:\t loss: 0.002172483131289482\n",
      "epoch: 1 iteration: 1441:\t loss: 0.001858144998550415\n",
      "epoch: 1 iteration: 1461:\t loss: 0.0018011711072176695\n",
      "epoch: 1 iteration: 1481:\t loss: 0.0015912940725684166\n",
      "epoch: 1 iteration: 1501:\t loss: 0.0022322076838463545\n",
      "epoch: 1 iteration: 1521:\t loss: 0.009361069649457932\n",
      "epoch: 1 iteration: 1541:\t loss: 0.0022704170551151037\n",
      "epoch: 1 iteration: 1561:\t loss: 0.0014240116579458117\n",
      "epoch: 1 iteration: 1581:\t loss: 0.00179089920129627\n",
      "epoch: 1 iteration: 1601:\t loss: 0.0018042332958430052\n",
      "epoch: 1 iteration: 1621:\t loss: 0.0021293542813509703\n",
      "epoch: 1 iteration: 1641:\t loss: 0.0024471734650433064\n",
      "epoch: 1 iteration: 1661:\t loss: 0.001963019371032715\n",
      "epoch: 1 iteration: 1681:\t loss: 0.0023552991915494204\n",
      "epoch: 1 iteration: 1701:\t loss: 0.0014172277878969908\n",
      "epoch: 1 iteration: 1721:\t loss: 0.001493183895945549\n",
      "epoch: 1 iteration: 1741:\t loss: 0.0020255502313375473\n",
      "epoch: 1 iteration: 1761:\t loss: 0.0019874058198183775\n",
      "epoch: 1 iteration: 1781:\t loss: 0.0014496867079287767\n",
      "epoch: 1 iteration: 1801:\t loss: 0.0015649484703317285\n",
      "epoch: 1 iteration: 1821:\t loss: 0.0017986104357987642\n",
      "epoch: 1 iteration: 1841:\t loss: 0.0017258601728826761\n",
      "epoch: 1 iteration: 1861:\t loss: 0.001545424573123455\n",
      "epoch: 1 iteration: 1881:\t loss: 0.0017425133846700191\n",
      "epoch: 1 iteration: 1901:\t loss: 0.0013408070662990212\n",
      "epoch: 1 iteration: 1921:\t loss: 0.0016758551355451345\n",
      "epoch: 1 iteration: 1941:\t loss: 0.001441455096937716\n",
      "epoch: 1 iteration: 1961:\t loss: 0.001473585027270019\n",
      "epoch: 1 iteration: 1981:\t loss: 0.009705794043838978\n",
      "epoch: 1 iteration: 2001:\t loss: 0.001400480978190899\n",
      "epoch: 1 iteration: 2021:\t loss: 0.0014641584130004048\n",
      "epoch: 1 iteration: 2041:\t loss: 0.0015030279755592346\n",
      "epoch: 1 iteration: 2061:\t loss: 0.0015161429764702916\n",
      "epoch: 1 iteration: 2081:\t loss: 0.0014309041434898973\n",
      "epoch: 1 iteration: 2101:\t loss: 0.00919188279658556\n",
      "epoch: 1 iteration: 2121:\t loss: 0.0013342504389584064\n",
      "epoch: 1 iteration: 2141:\t loss: 0.009044095873832703\n",
      "epoch: 1 iteration: 2161:\t loss: 0.0013690037885680795\n",
      "epoch: 1 iteration: 2181:\t loss: 0.0014993366785347462\n",
      "epoch: 1 iteration: 2201:\t loss: 0.0017040744423866272\n",
      "epoch: 1 iteration: 2221:\t loss: 0.00930563174188137\n",
      "epoch: 1 iteration: 2241:\t loss: 0.0015351006295531988\n",
      "epoch: 1 iteration: 2261:\t loss: 0.009192387573421001\n",
      "epoch: 1 iteration: 2281:\t loss: 0.0015399500261992216\n",
      "epoch: 1 iteration: 2301:\t loss: 0.0013961840886622667\n",
      "epoch: 1 iteration: 2321:\t loss: 0.0012201531790196896\n",
      "epoch: 1 iteration: 2341:\t loss: 0.0011117387330159545\n",
      "epoch: 1 iteration: 2361:\t loss: 0.00881405733525753\n",
      "epoch: 1 iteration: 2381:\t loss: 0.009188549593091011\n",
      "epoch: 1 iteration: 2401:\t loss: 0.0093820346519351\n",
      "epoch: 1 iteration: 2421:\t loss: 0.0010394122218713164\n",
      "epoch: 1 iteration: 2441:\t loss: 0.0009337671217508614\n",
      "epoch: 1 iteration: 2461:\t loss: 0.001265120692551136\n",
      "epoch: 1 iteration: 2481:\t loss: 0.0012519576121121645\n",
      "epoch: 1 iteration: 2501:\t loss: 0.0010588672012090683\n",
      "epoch: 1 iteration: 2521:\t loss: 0.0010467320680618286\n",
      "epoch: 1 iteration: 2541:\t loss: 0.001271042157895863\n",
      "epoch: 1 iteration: 2561:\t loss: 0.0009946931386366487\n",
      "epoch: 1 iteration: 2581:\t loss: 0.0008598193526268005\n",
      "epoch: 1 iteration: 2601:\t loss: 0.0009339288808405399\n",
      "epoch: 1 iteration: 2621:\t loss: 0.0010605788556858897\n",
      "epoch: 1 iteration: 2641:\t loss: 0.0010433244751766324\n",
      "epoch: 1 iteration: 2661:\t loss: 0.0008684429922141135\n",
      "epoch: 1 iteration: 2681:\t loss: 0.0012985330540686846\n",
      "epoch: 1 iteration: 2701:\t loss: 0.0007714726962149143\n",
      "epoch: 1 iteration: 2721:\t loss: 0.0010937885381281376\n",
      "epoch: 1 iteration: 2741:\t loss: 0.0009797983802855015\n",
      "epoch: 1 iteration: 2761:\t loss: 0.0008317667525261641\n",
      "epoch: 1 iteration: 2781:\t loss: 0.0009092900436371565\n",
      "epoch: 1 iteration: 2801:\t loss: 0.0008671656833030283\n",
      "epoch: 1 iteration: 2821:\t loss: 0.0008391896262764931\n",
      "epoch: 1 iteration: 2841:\t loss: 0.0007511785952374339\n",
      "epoch: 1 iteration: 2861:\t loss: 0.0009084701305255294\n",
      "epoch: 1 iteration: 2881:\t loss: 0.0008201373275369406\n",
      "epoch: 1 iteration: 2901:\t loss: 0.008669918403029442\n",
      "epoch: 1 iteration: 2921:\t loss: 0.008372007869184017\n",
      "epoch: 1 iteration: 2941:\t loss: 0.0008046018774621189\n",
      "epoch: 1 iteration: 2961:\t loss: 0.000730385072529316\n",
      "epoch: 1 iteration: 2981:\t loss: 0.0010164014529436827\n",
      "epoch: 1 iteration: 3001:\t loss: 0.0008194366237148643\n",
      "epoch: 1 iteration: 3021:\t loss: 0.0010540010407567024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 iteration: 3041:\t loss: 0.0007029303815215826\n",
      "epoch: 1 iteration: 3061:\t loss: 0.0006959307938814163\n",
      "epoch: 1 iteration: 3081:\t loss: 0.0006157582392916083\n",
      "epoch: 1 iteration: 3101:\t loss: 0.0007240409031510353\n",
      "epoch: 1 iteration: 3121:\t loss: 0.0005748536204919219\n",
      "epoch: 1 iteration: 3141:\t loss: 0.0006498704897239804\n",
      "epoch: 1 iteration: 3161:\t loss: 0.0007801440078765154\n",
      "epoch: 1 iteration: 3181:\t loss: 0.0007305170292966068\n",
      "epoch: 1 iteration: 3201:\t loss: 0.0006723920814692974\n",
      "epoch: 1 iteration: 3221:\t loss: 0.0006233346648514271\n",
      "epoch: 1 iteration: 3241:\t loss: 0.0006971961120143533\n",
      "epoch: 1 iteration: 3261:\t loss: 0.0004971391172148287\n",
      "epoch: 1 iteration: 3281:\t loss: 0.0006901094457134604\n",
      "epoch: 1 iteration: 3301:\t loss: 0.0006691628368571401\n",
      "epoch: 1 iteration: 3321:\t loss: 0.0007496462785638869\n",
      "epoch: 1 iteration: 3341:\t loss: 0.000564581947401166\n",
      "epoch: 1 iteration: 3361:\t loss: 0.0005485893925651908\n",
      "epoch: 1 iteration: 3381:\t loss: 0.0005727818934246898\n",
      "epoch: 1 iteration: 3401:\t loss: 0.0005785010871477425\n",
      "epoch: 1 iteration: 3421:\t loss: 0.0006614988669753075\n",
      "epoch: 1 iteration: 3441:\t loss: 0.0008139311103150249\n",
      "epoch: 1 iteration: 3461:\t loss: 0.0005852228496223688\n",
      "epoch: 1 iteration: 3481:\t loss: 0.0006079340819269419\n",
      "epoch: 1 iteration: 3501:\t loss: 0.0004916375037282705\n",
      "epoch: 1 iteration: 3521:\t loss: 0.0006044066976755857\n",
      "epoch: 1 iteration: 3541:\t loss: 0.0004430941480677575\n",
      "epoch: 1 iteration: 3561:\t loss: 0.008391059003770351\n",
      "epoch: 1 iteration: 3581:\t loss: 0.0007375259883701801\n",
      "epoch: 1 iteration: 3601:\t loss: 0.0005425597773864865\n",
      "epoch: 1 iteration: 3621:\t loss: 0.008606147021055222\n",
      "epoch: 1 iteration: 3641:\t loss: 0.00822127889841795\n",
      "epoch: 1 iteration: 3661:\t loss: 0.008287123404443264\n",
      "epoch: 1 iteration: 3681:\t loss: 0.0005260429461486638\n",
      "epoch: 1 iteration: 3701:\t loss: 0.0003888538049068302\n",
      "epoch: 1 iteration: 3721:\t loss: 0.015993906185030937\n",
      "epoch: 1 iteration: 3741:\t loss: 0.0005705388030037284\n",
      "epoch: 1 iteration: 3761:\t loss: 0.0004395211872179061\n",
      "epoch: 1 iteration: 3781:\t loss: 0.0003588192630559206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwangiy/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([9])) that is different to the input size (torch.Size([9, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 iteration: 3801:\t loss: 0.0006403698353096843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwangiy/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([78])) that is different to the input size (torch.Size([78, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.001222).  Saving model ...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory ./cnn_model does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:4\u001b[0m\n",
      "File \u001b[0;32m~/Reimage/my_reimagine/project/notebooks/../trainers/trainer_reg.py:157\u001b[0m, in \u001b[0;36mTrain.main\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel()\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m-^60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvaluate Model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m-^60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m~/Reimage/my_reimagine/project/notebooks/../trainers/trainer_reg.py:72\u001b[0m, in \u001b[0;36mTrain.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m loss_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_count[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_loss_train\u001b[38;5;241m.\u001b[39mappend(loss_train)\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopping(loss_val, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopping\u001b[38;5;241m.\u001b[39mearly_stop:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEarly stopping\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Reimage/my_reimagine/project/notebooks/../utils/utils.py:61\u001b[0m, in \u001b[0;36mEarlyStopping.__call__\u001b[0;34m(self, val_loss, model)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_score \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_score \u001b[38;5;241m=\u001b[39m score\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_checkpoint(val_loss, model)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m score \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_score \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelta:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcounter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Reimage/my_reimagine/project/notebooks/../utils/utils.py:77\u001b[0m, in \u001b[0;36mEarlyStopping.save_checkpoint\u001b[0;34m(self, val_loss, model)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation loss decreased (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_loss_min\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m --> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).  Saving model ...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m#         torch.save(model.state_dict(), self.path)\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m         torch\u001b[38;5;241m.\u001b[39msave(model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath)\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_loss_min \u001b[38;5;241m=\u001b[39m val_loss\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/serialization.py:618\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    615\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    619\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    620\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/serialization.py:492\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    491\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m container(name_or_buffer)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/serialization.py:463\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory ./cnn_model does not exist."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from trainers.trainer_reg import Train\n",
    "\n",
    "train = Train()\n",
    "train.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da01aa6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20aab25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fa8dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea881ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
